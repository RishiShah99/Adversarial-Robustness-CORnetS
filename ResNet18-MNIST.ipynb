{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":135693,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":114791,"modelId":138052}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:22:23.366897Z","iopub.execute_input":"2025-07-04T03:22:23.367220Z","iopub.status.idle":"2025-07-04T03:22:28.217822Z","shell.execute_reply.started":"2025-07-04T03:22:23.367194Z","shell.execute_reply":"2025-07-04T03:22:28.216879Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Loading the dataset and Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Define transformations\ntransform = transforms.Compose([\n    transforms.ToTensor(), # Convert images to tensors\n    transforms.Normalize((0.5,), (0.5,)) # Normalize the images to [-1, 1]\n])","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:22:29.462023Z","iopub.execute_input":"2025-07-04T03:22:29.462676Z","iopub.status.idle":"2025-07-04T03:22:29.467209Z","shell.execute_reply.started":"2025-07-04T03:22:29.462650Z","shell.execute_reply":"2025-07-04T03:22:29.466251Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load MNIST training dataset\ntrain_dataset = torchvision.datasets.MNIST(\n    root='./data', train=True, download=True, transform=transform\n)","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:22:30.433462Z","iopub.execute_input":"2025-07-04T03:22:30.434204Z","iopub.status.idle":"2025-07-04T03:22:32.824745Z","shell.execute_reply.started":"2025-07-04T03:22:30.434164Z","shell.execute_reply":"2025-07-04T03:22:32.823842Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 35239716.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 1067886.40it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Failed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 9096254.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 3931186.29it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load MNIST test dataset\ntest_dataset = torchvision.datasets.MNIST(\n    root='./data', train=False, download=True, transform=transform\n)","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:22:32.826250Z","iopub.execute_input":"2025-07-04T03:22:32.826499Z","iopub.status.idle":"2025-07-04T03:22:32.841104Z","shell.execute_reply.started":"2025-07-04T03:22:32.826474Z","shell.execute_reply":"2025-07-04T03:22:32.840469Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Create DataLoader for training set\ntrain_loader = DataLoader(\n    dataset=train_dataset, batch_size=64, shuffle=True\n)\n\n# Create DataLoader for test set\ntest_loader = DataLoader(\n    dataset=test_dataset, batch_size=64, shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:22:35.186233Z","iopub.execute_input":"2025-07-04T03:22:35.186783Z","iopub.status.idle":"2025-07-04T03:22:35.191082Z","shell.execute_reply.started":"2025-07-04T03:22:35.186755Z","shell.execute_reply":"2025-07-04T03:22:35.190220Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Modifying ResNet model for MNIST dataset","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\n\n# Load the pre-trained ResNet18 model\nmodel = models.resnet18(pretrained=True)\n\n# Modify the first convolutional layer to accept 1 channel (grayscale)\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# Modify the fully connected layer for 10 output classes (MNIST)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 10)\n\n# Move model to the GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:22:38.437181Z","iopub.execute_input":"2025-07-04T03:22:38.437784Z","iopub.status.idle":"2025-07-04T03:22:39.436038Z","shell.execute_reply.started":"2025-07-04T03:22:38.437757Z","shell.execute_reply":"2025-07-04T03:22:39.435248Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 158MB/s] \n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# Model Setup","metadata":{}},{"cell_type":"code","source":"# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:22:45.885731Z","iopub.execute_input":"2025-07-04T03:22:45.886299Z","iopub.status.idle":"2025-07-04T03:22:45.891238Z","shell.execute_reply.started":"2025-07-04T03:22:45.886271Z","shell.execute_reply":"2025-07-04T03:22:45.890342Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"# Number of epochs\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    # Print loss for the epoch\n    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:08:42.949170Z","iopub.execute_input":"2024-10-05T18:08:42.949492Z","iopub.status.idle":"2024-10-05T18:13:16.085790Z","shell.execute_reply.started":"2024-10-05T18:08:42.949462Z","shell.execute_reply":"2024-10-05T18:13:16.084837Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.1794\nEpoch [2/10], Loss: 0.0733\nEpoch [3/10], Loss: 0.0549\nEpoch [4/10], Loss: 0.0462\nEpoch [5/10], Loss: 0.0360\nEpoch [6/10], Loss: 0.0336\nEpoch [7/10], Loss: 0.0264\nEpoch [8/10], Loss: 0.0250\nEpoch [9/10], Loss: 0.0255\nEpoch [10/10], Loss: 0.0238\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Testing Loop","metadata":{}},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = correct / total\nprint(f'Accuracy on the test set: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:23:13.076188Z","iopub.execute_input":"2025-07-04T03:23:13.076511Z","iopub.status.idle":"2025-07-04T03:23:16.734831Z","shell.execute_reply.started":"2025-07-04T03:23:13.076485Z","shell.execute_reply":"2025-07-04T03:23:16.733977Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy on the test set: 99.23%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Saving the Model","metadata":{}},{"cell_type":"code","source":"# Save the trained model\ntorch.save(model.state_dict(), 'mnist_resnet18.pth')\nprint(\"Model saved successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:13:18.931993Z","iopub.execute_input":"2024-10-05T18:13:18.932335Z","iopub.status.idle":"2024-10-05T18:13:19.029739Z","shell.execute_reply.started":"2024-10-05T18:13:18.932309Z","shell.execute_reply":"2024-10-05T18:13:19.028741Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model saved successfully!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# PGD Adversarial Attacks onto the Model","metadata":{}},{"cell_type":"code","source":"!pip install torchattacks","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:22:53.455307Z","iopub.execute_input":"2025-07-04T03:22:53.455975Z","iopub.status.idle":"2025-07-04T03:23:04.471798Z","shell.execute_reply.started":"2025-07-04T03:22:53.455950Z","shell.execute_reply":"2025-07-04T03:23:04.470691Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting torchattacks\n  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (2.1.2)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (0.16.2)\nRequirement already satisfied: scipy>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.11.4)\nRequirement already satisfied: tqdm>=4.56.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (4.66.4)\nCollecting requests~=2.25.1 (from torchattacks)\n  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.26.4)\nCollecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (2024.5.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8.2->torchattacks) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\nDownloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: idna, chardet, requests, torchattacks\n  Attempting uninstall: idna\n    Found existing installation: idna 3.6\n    Uninstalling idna-3.6:\n      Successfully uninstalled idna-3.6\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.3\n    Uninstalling requests-2.32.3:\n      Successfully uninstalled requests-2.32.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.3 which is incompatible.\nconda 24.5.0 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\nconda 24.5.0 requires requests<3,>=2.28.0, but you have requests 2.25.1 which is incompatible.\ndatasets 2.20.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\ndocker 7.0.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-server 2.27.2 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.5.1\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torchattacks\nfrom torchattacks import PGD, CW","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:23:04.474174Z","iopub.execute_input":"2025-07-04T03:23:04.475011Z","iopub.status.idle":"2025-07-04T03:23:04.954419Z","shell.execute_reply.started":"2025-07-04T03:23:04.474973Z","shell.execute_reply":"2025-07-04T03:23:04.953725Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torchvision.models as models\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Define the model structure\nmodel = models.resnet18()\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 10)\n\n# Load the trained model weights\nmodel.load_state_dict(torch.load('/kaggle/input/mnist_resnet18/pytorch/default/1/mnist_resnet18.pth'))\nmodel.to(device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:23:04.955468Z","iopub.execute_input":"2025-07-04T03:23:04.955717Z","iopub.status.idle":"2025-07-04T03:23:05.971790Z","shell.execute_reply.started":"2025-07-04T03:23:04.955696Z","shell.execute_reply":"2025-07-04T03:23:05.970946Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\nimport time\n\n# Define the PGD attack\npgd = torchattacks.PGD(model, eps=0.1, alpha=2/255, steps=40)\n\n# Function to evaluate the model under attack with a progress bar\ndef evaluate_under_attack(loader, model, attack):\n    model.eval()\n    correct = 0\n    total = 0\n    batch_times = []\n    progress_bar = tqdm(enumerate(loader), total=len(loader), desc=\"Evaluating\")\n    \n    for i, (inputs, labels) in progress_bar:\n        start_time = time.time()\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Enable gradients for the inputs\n        inputs.requires_grad = True\n        \n        adv_inputs = attack(inputs, labels)\n        outputs = model(adv_inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Disable gradients for the inputs\n        inputs.requires_grad = False\n\n        batch_time = time.time() - start_time\n        batch_times.append(batch_time)\n        \n        # Update progress bar with batch accuracy and average batch time\n        progress_bar.set_postfix(batch_accuracy=(correct / total), avg_batch_time=sum(batch_times) / len(batch_times))\n    \n    accuracy = correct / total\n    return accuracy\n\n# Evaluate the model under PGD attack\nadv_accuracy = evaluate_under_attack(test_loader, model, pgd)\nprint(f'Adversarial Accuracy under PGD Attack: {adv_accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2025-07-04T03:23:30.849778Z","iopub.execute_input":"2025-07-04T03:23:30.850120Z","iopub.status.idle":"2025-07-04T03:24:32.735615Z","shell.execute_reply.started":"2025-07-04T03:23:30.850092Z","shell.execute_reply":"2025-07-04T03:24:32.734701Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 157/157 [01:01<00:00,  2.54it/s, avg_batch_time=0.38, batch_accuracy=0.606] ","output_type":"stream"},{"name":"stdout","text":"Adversarial Accuracy under PGD Attack: 60.59%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\n\n# Define FGSM attack\nfgsm = torchattacks.FGSM(model, eps=0.3)\n\n# Function to evaluate under FGSM attack with TQDM\ndef evaluate_under_attack(loader, model, attack):\n    model.eval()\n    correct = 0\n    total = 0\n    progress_bar = tqdm(enumerate(loader), total=len(loader), desc=\"Evaluating\")\n    for i, (inputs, labels) in progress_bar:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Generate adversarial examples if attack is specified\n        if attack:\n            adv_inputs = attack(inputs, labels)\n        else:\n            adv_inputs = inputs\n        \n        outputs = model(adv_inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Update the progress bar with current accuracy\n        progress_bar.set_postfix(batch_accuracy=(correct / total))\n    \n    return correct / total\n\n# Test the model under FGSM attack\naccuracy_fgsm = evaluate_under_attack(test_loader, model, fgsm)\nprint(f'Accuracy under FGSM Attack: {accuracy_fgsm * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T22:29:23.866035Z","iopub.execute_input":"2024-12-14T22:29:23.866798Z","iopub.status.idle":"2024-12-14T22:29:29.205699Z","shell.execute_reply.started":"2024-12-14T22:29:23.866770Z","shell.execute_reply":"2024-12-14T22:29:29.204901Z"}},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 157/157 [00:05<00:00, 29.48it/s, batch_accuracy=0.499]","output_type":"stream"},{"name":"stdout","text":"Accuracy under FGSM Attack: 49.87%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Carlini Wagner Attack","metadata":{}},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\nimport time\n\n# Define the Carlini-Wagner attack\ncw = torchattacks.CW(model, c=1e-3, kappa=0, steps=100, lr=0.01)\n\n# Function to evaluate the model under CW attack with a progress bar\ndef evaluate_under_attack(loader, model, attack):\n    model.eval()\n    correct = 0\n    total = 0\n    batch_times = []\n    progress_bar = tqdm(enumerate(loader), total=len(loader), desc=\"Evaluating\")\n    \n    for i, (inputs, labels) in progress_bar:\n        start_time = time.time()\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Enable gradients for the inputs\n        inputs.requires_grad = True\n        \n        adv_inputs = attack(inputs, labels)\n        outputs = model(adv_inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Disable gradients for the inputs\n        inputs.requires_grad = False\n\n        batch_time = time.time() - start_time\n        batch_times.append(batch_time)\n        \n        # Update progress bar with batch accuracy and average batch time\n        progress_bar.set_postfix(batch_accuracy=(correct / total), avg_batch_time=sum(batch_times) / len(batch_times))\n    \n    accuracy = correct / total\n    return accuracy\n\n# Evaluate the model under CW attack\ncw_accuracy = evaluate_under_attack(test_loader, model, cw)\nprint(f'Adversarial Accuracy under CW Attack: {cw_accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2025-04-08T21:25:25.401444Z","iopub.execute_input":"2025-04-08T21:25:25.402375Z","iopub.status.idle":"2025-04-08T21:25:55.565247Z","shell.execute_reply.started":"2025-04-08T21:25:25.402342Z","shell.execute_reply":"2025-04-08T21:25:55.564338Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 157/157 [00:30<00:00,  5.21it/s, avg_batch_time=0.176, batch_accuracy=0.798]","output_type":"stream"},{"name":"stdout","text":"Adversarial Accuracy under CW Attack: 79.81%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Visualizing All Images","metadata":{}},{"cell_type":"markdown","source":"## Visualizing Original Images with Labels","metadata":{}},{"cell_type":"code","source":"# Function to unnormalize and visualize images\ndef imshow(img, title=None):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    if title is not None:\n        plt.title(title)\n    plt.show()\n\n# Visualize a few original dataset images with their labels\ndef visualize_original_images(loader, num_images=5):\n    dataiter = iter(loader)\n    images, labels = next(dataiter)  # Use next() to get the next batch\n    images, labels = images[:num_images], labels[:num_images]\n    imshow(torchvision.utils.make_grid(images), title=[str(int(label)) for label in labels])\n\n# Visualize original images\n# visualize_original_images(test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:54:44.414467Z","iopub.execute_input":"2024-10-05T18:54:44.415103Z","iopub.status.idle":"2024-10-05T18:54:44.422474Z","shell.execute_reply.started":"2024-10-05T18:54:44.415072Z","shell.execute_reply":"2024-10-05T18:54:44.421507Z"},"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## Visualizing The Model's Predictions","metadata":{}},{"cell_type":"code","source":"# Visualize the model's predictions on original images\ndef visualize_model_predictions(model, loader, num_images=5):\n    model.eval()\n    dataiter = iter(loader)\n    images, labels = next(dataiter)  # Use next() to get the next batch\n    images, labels = images[:num_images], labels[:num_images]\n    images, labels = images.to(device), labels.to(device)\n\n    outputs = model(images)\n    _, predicted = torch.max(outputs, 1)\n    predicted = predicted.cpu().numpy()\n\n    imshow(torchvision.utils.make_grid(images.cpu()), title=[str(pred) for pred in predicted])","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:27:54.192947Z","iopub.status.idle":"2024-10-05T18:27:54.193469Z","shell.execute_reply.started":"2024-10-05T18:27:54.193218Z","shell.execute_reply":"2024-10-05T18:27:54.193240Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize model predictions on original images\nvisualize_model_predictions(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:27:54.195352Z","iopub.status.idle":"2024-10-05T18:27:54.195736Z","shell.execute_reply.started":"2024-10-05T18:27:54.195550Z","shell.execute_reply":"2024-10-05T18:27:54.195567Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizing PGD Adversarial Attacks","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n# Visualize adversarial examples generated by PGD attack\ndef visualize_pgd_attack(model, loader, attack, num_images=5):\n    model.eval()\n    dataiter = iter(loader)\n    images, labels = next(dataiter)  # Use next() to get the next batch\n    images, labels = images[:num_images], labels[:num_images]\n    images, labels = images.to(device), labels.to(device)\n\n    adv_images = attack(images, labels)\n    outputs = model(adv_images)\n    _, predicted = torch.max(outputs, 1)\n    predicted = predicted.cpu().numpy()\n\n    imshow(torchvision.utils.make_grid(adv_images.cpu()), title=[str(pred) for pred in predicted])","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:55:52.422562Z","iopub.execute_input":"2024-10-05T18:55:52.423481Z","iopub.status.idle":"2024-10-05T18:55:52.430753Z","shell.execute_reply.started":"2024-10-05T18:55:52.423441Z","shell.execute_reply":"2024-10-05T18:55:52.429776Z"},"trusted":true},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Define PGD attacks\npgd = torchattacks.PGD(model, eps=1.06, alpha=6/255, steps=40)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:55:52.707440Z","iopub.execute_input":"2024-10-05T18:55:52.707811Z","iopub.status.idle":"2024-10-05T18:55:52.712420Z","shell.execute_reply.started":"2024-10-05T18:55:52.707781Z","shell.execute_reply":"2024-10-05T18:55:52.711544Z"},"trusted":true},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Visualize PGD attack\nvisualize_pgd_attack(model, test_loader, pgd)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:55:53.034824Z","iopub.execute_input":"2024-10-05T18:55:53.035171Z","iopub.status.idle":"2024-10-05T18:55:53.610202Z","shell.execute_reply.started":"2024-10-05T18:55:53.035144Z","shell.execute_reply":"2024-10-05T18:55:53.609066Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAh8AAACqCAYAAAANxS0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAg00lEQVR4nO3deVjVVf4H8PdlR2URTRARoU1SzFRM0RZncrJ5nMx0psZRR1qmsQEXKEMbTRtzzSZzScem1EezxUYrbaqHEEEbcQF3C51CQBFwYXNhiXt+f/TzzPleFgHvPZfLfb+ex+f53O9yz7mHuHz6ns0khBAgIiIi0sTF3hUgIiIi58Lkg4iIiLRi8kFERERaMfkgIiIirZh8EBERkVZMPoiIiEgrJh9ERESkFZMPIiIi0orJBxEREWnF5IPoJsXExMBkMsFkMiEyMtLe1SEHt3TpUvnfk8lkwoULF+xdJSKrY/JBZAUdO3bEhg0bsHDhQsPxsLAwzJkzx3Bs3rx5GDFiBAIDA2EymWqdvy4mJgZDhgxpVn3WrVsHk8lU7/nq6mr06NEDJpMJS5YsMZzbuXMnTCYTTp8+3ayyTSYT1q1bV+/5efPm1Zuo1dVejXWj9vrhhx/g5eUFk8mEAwcOGM7NmTMHYWFhzSq3rvbKyspCfHw8Bg0aJMusrz0t2+uRRx7Bhg0b8PjjjzerPkSOgMkHkRW0bdsW48aNw29+85sbXjtz5kzs378fffr00VCzui1fvhy5ubnayz1z5gzmz5+Ptm3bai87Pj4ebm5uWsras2cPli1bhvLyctx1111NujciIgLjxo3D3XffbaPaEdkfkw8izbKzs3Hu3Dls3LjRLuUXFRXhb3/7GxITE7WX/eKLL2LgwIGIiorSWu7XX3+Nr7/+GvHx8VrKGzFiBEpKSnD06FGMHTtWS5lEjoTJB5FmzX28by3Tp09H9+7dMW7cOK3lpqWl4ZNPPsHSpUu1lltdXY0pU6ZgypQpuO2227SUGRAQAB8fHy1lETkiJh9ETmTfvn1Yv369HNSoS01NDSZNmoRnn30WvXr10lYu8PMAzuLiYsycOVNruURUPz0doEROqrmDNgE0OGjzRmJiYhATE2M4JoTApEmT8OSTTyI6Orreug0ZMgRCiGaXXde9q1evRk5ODr755psG77V2exUUFGDu3LlYsmQJfH196713zpw5zR7oaov2ImrtmHwQOYl169bh6NGj+OSTT7SWe/HiRbzyyiuYNWsWbrnlFq1lJyYm4tZbb8Wzzz6rtVwiahiTDyInUFZWhhkzZmDatGno2rWr1rJnzpyJgIAATJo0SWu56enp2LBhA5KTk+Hiwh5mopaEyQeRE1iyZAmqqqrw5JNPyq6NM2fOAACKi4tx+vRpBAcHw8PDw6rlnjp1CmvWrMHSpUuRn58vj1dUVKC6uhqnT5+Gr68vAgICrFouALz00ku4//77ER4eLj/z9QW7zp07h9zcXISGhlq9XCK6MSYfRE4gNzcXxcXF6NmzZ61z8+fPx/z583Hw4EHcc889Vi337NmzMJvNmDx5MiZPnlzrfHh4OKZMmWKTGTC5ubnIyclBeHh4rXMjRoyAn58fSkpKrF4uEd0Ykw8iJzB58mSMHDnScKyoqAh//vOfERMTg8cee6zOP9I3KzIyElu3bq11fObMmSgvL8dbb71ls+mva9aswdWrVw3HduzYgeXLl2PJkiWIiIiwSblEdGNMPog027BhA3JycuQfxrS0NLz22msAgPHjx6Nbt2713hsTE4P169cjOzu7SeuF9O3bF3379jUcu94V0bNnz1qJiaWdO3fiF7/4BWbPnt2kWSEdO3as872vP+m4UbnA/9ZFaepMmIcffrjWsetPOh588MEbLnQ2Z84cvPrqq0hJSWnyMvelpaVYvnw5AODbb78FAKxYsQL+/v7w9/dHXFxck96PqLVh8kGk2bvvvovU1FT5OiUlBSkpKQCA++67r8Hk4/Lly/D29oa/v7+tq1mrXADo3Lmz1nIB4MqVK7j99tu1l3v58mWYTCYEBQU1+d7i4mLMmjXLcOyNN94AAHTr1o3JBzk9Jh9EVmA2m3HhwgW4ubndMDHYuXNns8vZtWsXYmNjrZJ8hIWFNXqNibS0NISEhNRaO6S5GtsGJ06cwIULF25qzRNVXeuf1CctLQ2jR49uVvdMU9rWUkVFBS5fvlyry4ioNWHyQWQFeXl5uOWWW9CzZ08cO3bMJmUcP34c165ds8ueLCkpKZg1axY8PT21lxsdHY3hw4drLbesrAyHDx/G+vXrtZYL/Lwgm649aIjsxSS4vB7RTTlx4oScRtquXTsMHDjQzjUiR5aXl4esrCz5+sEHH4S7u7sda0RkfUw+iIiISCsu+0dERERa2Sz5WLlyJcLCwuDl5YUBAwZg3759tiqKiIiIHIhNko+PPvoICQkJmD17NjIzM9G7d28MGzYMRUVFtiiOiIiIHIhNxnwMGDAA/fv3x4oVKwD8PA2xa9eumDRpEqZPn97gvWazGfn5+fDx8YHJZLJ21YiIiMgGhBAoLy9HcHDwDTdztPpU26qqKmRkZGDGjBnymIuLC4YOHYo9e/bUur6yshKVlZXy9dmzZ9GjRw9rV4uIiIg0yMvLQ0hISIPXWD35uHDhAmpqahAYGGg4HhgYiO+//77W9QsWLMCrr75a63h8fLz2NQWIiIioeSorK/Hmm2/Cx8fnhtfafZGxGTNmICEhQb4uKytD165d4enpyeSDiIjIwTRmyITVk4+OHTvC1dUVhYWFhuOFhYV17pHAJIOIiMi5WH22i4eHB/r164fk5GR5zGw2Izk5GdHR0dYujoiIiByMTbpdEhISMGHCBERFReHee+/F0qVLceXKFTz11FO2KI6IiIgciE2SjyeffBLnz5/HK6+8goKCAtxzzz346quvag1CJSIiIudjswGncXFxiIuLs9XbExERkYPi3i5ERESkFZMPIiIi0orJBxEREWnF5IOIiIi0YvJBREREWjH5ICIiIq2YfBAREZFWdt9Yjqg57r//fhnv2rXLcC44OFjG5eXlMvbw8JDxxYsXDfd0795dxllZWVarJxER1cYnH0RERKQVkw8iIiLSiskHERERacUxH+QwXF1dZZyZmSnjtm3bGq7r2bOnjCsrK2V86NAhGVvuO/Tee+/JuH379jIuLi5ufoXppsyZM0fGixcvlvHVq1ftUJvWR93oU/3dqqioMFx36dIlbXUi58EnH0RERKQVkw8iIiLSit0u1KIlJCTIeO3atTKuqqqq9x61qyUtLU3Gbdq0kfE333xjuMdkMsl44MCBMv7yyy+bWGOyBXa1NE9QUJDh9aOPPirjjRs3yrh///4yPnjwoO0r5gR8fHxkrE75tza1+8zy98SW5d4sPvkgIiIirZh8EBERkVbsdqEW7eOPP5ZxbGysjF977bV671G7WlTqI8lBgwYZzp09e1bG/fr1kzG7Xexn1apV9q6CQ/Ly8pLxxIkTDeeOHz9e5z1RUVEyru/3h5pGnTVny+6PwsJCm723LfHJBxEREWnF5IOIiIi0YvJBREREWnHMx/8LDQ01vC4rK5OxOnVTneKpTs8EgJ9++slGtXNe6u6zbm7/+8+1Xbt2Mr58+XKj3kudamv581b7Tb/66qsm15OaJywszPC6tLRUxg888ICMN2/erKtKDumWW26R8fnz5+u9Tp1irk7DbWjquqpPnz4y5pTc2iIjI2Xs7e0t49zcXJuV2atXLxm7uBifJxw+fNhm5d4sPvkgIiIirZh8EBERkVbsdvl/atcKYOxCUTddUh+lXbt2rVHvrXYXeHh4GM6p0z+7du0qY7W7AQBqampkrG6kFhAQIOP//ve/jaqPI1HbeO7cuTJW26Oxbr/9dhmr3WqAcYVHtRyyre7duxteR0dHy/jzzz/XXR2HpXYp/upXv6r3OnXTuIKCAhmrq3Gq33GWfvzxRxnfeeedMj558mTjK9uKdOjQwfBabV9dG/Ll5eXJ2PJnp067ttww0N745IOIiIi0YvJBREREWjl1t0vnzp1l7O/vbzjXnFXj6puBoT76augedZS65SMydbU8dWR6dnZ2k+vpqJrT1aKu8FhcXCxjX19fw3Vbtmy5qXKoedRuFkuZmZkaa+J4pk2bJuPVq1fLePDgwfXek5iYeMP3texOVrt5R44cKWP1O9KZul3U7nGz2Ww4p3Zf6eoGv/vuu2V8+vRpLWVaA598EBERkVZMPoiIiEgrp+52OXfuXJ1xc6ldLeoCZOpxdVQ6YJztoi58pW50BgC33nprnXVVH/NZ4zO0NupIcHVGy+LFiw3XqT8Hsi3LGQKq1jhjy1ZKSkpkrM5w+e6772R8xx13GO5RZ96pVqxYUW85V65ckXF4eLiMjxw50ui6tibqd7g6gw4AfvjhBy11UBcTU3+fTp06Zbiupc1wUfHJBxEREWnF5IOIiIi0YvJBREREWjn1mA9bEkLUebyhsQXq5kPqqqoA8P3338tY7YOl2oKDg2WsjvNQcYyH/Viu3qvauHGjxpo4FsuVS7t06SJjta9/yJAh9b6H+h3z3nvvNbkO3377rYzV7yTLjRrV1VMbu2ldS6ZucpiWliZjyzE0apvYkropoDq91tPTU0v51sAnH0RERKQVkw8iIiLSit0uLYi6KZDlBnSRkZEyTk9PlzFX4wTmzJljeP3BBx/Ued2aNWs01IZuZPbs2TLev3+/HWvS8qmP1xtaubS+rhbLTRJv9vtCneKpdvuUl5cbrnv55Zdl/Pbbb8u4qKjopsq3F7V7Rf0u7tatm+G648ePa6mP+vdBXa05KytLS/nWwCcfREREpBWTDyIiItKK3S4tiLpynuUoavVxHrtajBvy5eTkGM6NGTNGxpZdMmR/r776qr2r4JAqKysNr9WZDZs3b5axOuPC2t8VSUlJMlYf948aNcpwnbpSbUOzm1oytYtJ/f7t3r27jL/44gtt9VFXl3V3d5ex2pXlSLP4+OSDiIiItGLyQURERFqx28XOIiIiZJydnS1j9ZEmYNxEioAXX3xRxp9++qnhnL+/v97K0A098sgjMlYXqrKcJUFG6mJdy5Ytq/c6XQsPtm3bVsZTp06VseVGmGp3hKN2E6vdWn/6059k/Nprr9mjOoZuefVvxUMPPSRjdVPBlo5PPoiIiEgrJh9ERESkFZMPIiIi0opjPuxM3YCuR48eMs7Ly7NHdVq0Pn36yFidTmg51dbPz09bnahxvvrqKxmr06Sp8cxms72rYBijs2jRIhknJiYarquoqNBWJ1u5du2ajNVxHupYkOrqasM91vwZqSteA8a2V78LT548abUydeKTDyIiItKKyQcRERFpxW4XO+vfv7+MCwsLZfzTTz8Zrrtw4YK2OrUkrq6uMlYfd27btk3GgwYN0lonujF1SiYATJs2TcZcdbbx1LbauHGj4Vz79u1lbM0N+tTfOcA4VVb9vlI3MXv99dcN96jdMG+99ZaMi4uLrVZPnR544AEZHzhwQMaWq86qG75VVVXJ2MfHx3Cd+jo/P1/GHTt2lLFl97G6saC6gqzlJqSOgk8+iIiISCsmH0RERKQVu100u/322w2vc3NzZXzkyBEZc0XTn6mbOB09erTOa9TNrup6TfrFxMTUe07tSmAXTMPUx/ojRowwnHv33Xe11OHpp5+W8fnz52U8fPjweu+ZO3eujB11hVPVjz/+KGN18zbLLip1Q1C1W8xywzfLjUOvU7ul1BVNAWDnzp0yDgwMlHF934stHZ98EBERkVZNSj4WLFiA/v37w8fHB506dcLIkSMNg46An+d3x8bGokOHDmjXrh1Gjx5tGEhJREREzq1JyUdqaipiY2ORnp6OpKQkVFdX4+GHHzZsahQfH49t27Zh8+bNSE1NRX5+PkaNGmX1ihMREZFjatKYD3WVQgBYt24dOnXqhIyMDDzwwAMoLS3Fu+++i02bNuGXv/wlAGDt2rW46667kJ6ejoEDB1qv5g5EnaZlOeVK7UtU+/E45uNnTzzxRJ3HLaf2UcuycuVKw2t1VVN1R2Jq2IoVK2T82GOPGc6NHj1axu+9995NlRMWFibj0NBQw7mPP/5YxpMmTZKxusKpuusr0DrGeajOnDlT53HLz6mO7QgODpax5dP/+tpHPe7iYnw2MGbMGBmr4z8c1U2N+SgtLQUABAQEAAAyMjJQXV2NoUOHymsiIiIQGhqKPXv21PkelZWVKCsrM/wjIiKi1qvZyYfZbMbUqVMxePBgREZGAgAKCgrg4eEBf39/w7WBgYEoKCio830WLFgAPz8/+a9r167NrRIRERE5gGZPtY2NjcWxY8ewe/fum6rAjBkzkJCQIF+XlZW1ugQkPDxcxv/6178M59RHae+88462Ojk6dcVMy0fO9Q1wVqctqqulWp6rT0MrPwYFBcl44sSJ9b5Henq6jNWVEp1pBdsvvvjC3lVwGC+88IKM1Wn5gLF75L777pPx4cOH67y/Idu3b5exuuImUH83mbqKKadM16auQmrJcuptXdTVTgHjSrGtQbOSj7i4OGzfvh1paWkICQmRx4OCglBVVYWSkhLD04/CwkLDl7PK09Oz1h8CIiIiar2a1O0ihEBcXBy2bt2KHTt2GP6PHgD69esHd3d3JCcny2NZWVnIzc1FdHS0dWpMREREDq1JTz5iY2OxadMmfPbZZ/Dx8ZHjOPz8/ODt7Q0/Pz8888wzSEhIQEBAAHx9fTFp0iRER0c73UwXdYaLOnPFcvbGZ599pqtKDmn+/Pkyfvnll+u8Rl2BEQBSUlJk3KlTJxn/+9//lvGAAQMM93To0EHGarfNpUuXZOzt7W24R32dkZFR9wewoP4e7Nq1q1H3OAq1u9SyG8lyozlqnIZWg1U3k8vOzpax2tViuZGbuurmqVOnZHzu3DkZq//NA8ZZLexq0cdyRoy6sdzp06dlrP4cHUmTko9Vq1YBAIYMGWI4vnbtWrmc8ptvvgkXFxeMHj0alZWVGDZsGN5++22rVJaIiIgcX5OSDyHEDa/x8vLCypUra83zJyIiIgK4sZxVqYNsMzMzZdy3b18ZW2561phRz86sqqpKxurCYrfddpuMLVfQVWeR/Pa3v63zfS27XZYtWybjyZMn13l80KBBhnvS0tJkbDab6/4AFtQp5+rKwK3BM88806jr+Li+eSzbTe32s1yQ6rqGBvOr30Xq/deuXTNc94c//EHGfIqtz8GDBw2v1UkbrWE9LG4sR0RERFox+SAiIiKtmHwQERGRVhzzcROu72lznZ+fX53n1LEB1Hy9e/eWcb9+/WTc0BiC9evXy1jd1C8rK8tw3Z133iljdaVZ9WdqOV6nPs46puHs2bMy7tKli+Gcs7aJLaljM9SpzN9++62M1emZgHFqf3l5uYzrGzMCAJs2bbqpepJ1qKswV1RU2LEm1sEnH0RERKQVkw8iIiLSit0uN8Fy1cbz58/LuLS0VHd1Wr3//Oc/dcaNpT5m3rJli1XqRP+jdrVcX5CQ9FAfw1t2tagsp29Sy/X8888bXqs/u5ycHBmrq9M6Ej75ICIiIq2YfBAREZFWJtGYNdM1Kisrg5+fH6ZPn97g6nz2cs8998jY19fXcO7w4cMyjoyMlLE6+pyIiKip2rRpI+OWujJ2ZWUlFi5ciNLS0lp/Hy3xyQcRERFpxeSDiIiItGLyQURERFpxqm0Tubu7y/jixYuGc/Hx8TJWdx08ffq0jNVVIImIiBqjpY7zaC4++SAiIiKtmHwQERGRVux2aSJ1cx9XV1fDucLCQhn/85//lHF1dbXtK0ZEROQg+OSDiIiItGLyQURERFqx26WJjhw50qxzRERE9DM++SAiIiKtmHwQERGRVkw+iIiISCsmH0RERKQVkw8iIiLSiskHERERacXkg4iIiLRi8kFERERatbhFxoQQAIx7qBAREVHLdv3v9vW/4w0xicZcpdGZM2fQtWtXe1eDiIiImiEvLw8hISENXtPikg+z2Yz8/HwIIRAaGoq8vDz4+vrau1p2UVZWhq5du7INnLwNALYDwDYA2AYA2+C6ltgOQgiUl5cjODgYLi4Nj+pocd0uLi4uCAkJQVlZGQDA19e3xTSsvbAN2AbXsR3YBgDbAGAbXNfS2sHPz69R13HAKREREWnF5IOIiIi0arHJh6enJ2bPng1PT097V8Vu2AZsg+vYDmwDgG0AsA2uc/R2aHEDTomIiKh1a7FPPoiIiKh1YvJBREREWjH5ICIiIq2YfBAREZFWLTL5WLlyJcLCwuDl5YUBAwZg37599q6SzSxYsAD9+/eHj48POnXqhJEjRyIrK8twTUVFBWJjY9GhQwe0a9cOo0ePRmFhoZ1qbHsLFy6EyWTC1KlT5TFnaYOzZ89i3Lhx6NChA7y9vdGrVy8cOHBAnhdC4JVXXkHnzp3h7e2NoUOH4tSpU3assXXV1NRg1qxZCA8Ph7e3N2677TbMnTvXsFdEa2yDtLQ0PProowgODobJZMKnn35qON+Yz3zp0iWMHTsWvr6+8Pf3xzPPPIPLly9r/BQ3p6E2qK6uRmJiInr16oW2bdsiODgYf/zjH5Gfn294j9bcBpYmTpwIk8mEpUuXGo47Shu0uOTjo48+QkJCAmbPno3MzEz07t0bw4YNQ1FRkb2rZhOpqamIjY1Feno6kpKSUF1djYcffhhXrlyR18THx2Pbtm3YvHkzUlNTkZ+fj1GjRtmx1razf/9+/OMf/8Ddd99tOO4MbVBcXIzBgwfD3d0dX375JU6cOIE33ngD7du3l9csXrwYy5Ytw+rVq7F37160bdsWw4YNQ0VFhR1rbj2LFi3CqlWrsGLFCnz33XdYtGgRFi9ejOXLl8trWmMbXLlyBb1798bKlSvrPN+Yzzx27FgcP34cSUlJ2L59O9LS0vDcc8/p+gg3raE2uHr1KjIzMzFr1ixkZmZiy5YtyMrKwogRIwzXteY2UG3duhXp6ekIDg6udc5h2kC0MPfee6+IjY2Vr2tqakRwcLBYsGCBHWulT1FRkQAgUlNThRBClJSUCHd3d7F582Z5zXfffScAiD179tirmjZRXl4u7rjjDpGUlCQefPBBMWXKFCGE87RBYmKiuO++++o9bzabRVBQkHj99dflsZKSEuHp6Sk++OADHVW0ueHDh4unn37acGzUqFFi7NixQgjnaAMAYuvWrfJ1Yz7ziRMnBACxf/9+ec2XX34pTCaTOHv2rLa6W4tlG9Rl3759AoDIyckRQjhPG5w5c0Z06dJFHDt2THTr1k28+eab8pwjtUGLevJRVVWFjIwMDB06VB5zcXHB0KFDsWfPHjvWTJ/S0lIAQEBAAAAgIyMD1dXVhjaJiIhAaGhoq2uT2NhYDB8+3PBZAedpg88//xxRUVH43e9+h06dOqFPnz5455135Pns7GwUFBQY2sHPzw8DBgxoNe0waNAgJCcn4+TJkwCAw4cPY/fu3fj1r38NwDnawFJjPvOePXvg7++PqKgoec3QoUPh4uKCvXv3aq+zDqWlpTCZTPD39wfgHG1gNpsxfvx4TJs2DT179qx13pHaoEVtLHfhwgXU1NQgMDDQcDwwMBDff/+9nWqlj9lsxtSpUzF48GBERkYCAAoKCuDh4SF/wa4LDAxEQUGBHWppGx9++CEyMzOxf//+WuecpQ1+/PFHrFq1CgkJCXj55Zexf/9+TJ48GR4eHpgwYYL8rHX9frSWdpg+fTrKysoQEREBV1dX1NTUYN68eRg7diwAOEUbWGrMZy4oKECnTp0M593c3BAQENAq26WiogKJiYkYM2aM3FTNGdpg0aJFcHNzw+TJk+s870ht0KKSD2cXGxuLY8eOYffu3fauilZ5eXmYMmUKkpKS4OXlZe/q2I3ZbEZUVBTmz58PAOjTpw+OHTuG1atXY8KECXaunR4ff/wx3n//fWzatAk9e/bEoUOHMHXqVAQHBztNG1DDqqur8cQTT0AIgVWrVtm7OtpkZGTgrbfeQmZmJkwmk72rc9NaVLdLx44d4erqWmsWQ2FhIYKCguxUKz3i4uKwfft2pKSkICQkRB4PCgpCVVUVSkpKDNe3pjbJyMhAUVER+vbtCzc3N7i5uSE1NRXLli2Dm5sbAgMDW30bAEDnzp3Ro0cPw7G77roLubm5ACA/a2v+/Zg2bRqmT5+O3//+9+jVqxfGjx+P+Ph4LFiwAIBztIGlxnzmoKCgWoPyf/rpJ1y6dKlVtcv1xCMnJwdJSUmGreRbexvs2rULRUVFCA0Nld+TOTk5eOGFFxAWFgbAsdqgRSUfHh4e6NevH5KTk+Uxs9mM5ORkREdH27FmtiOEQFxcHLZu3YodO3YgPDzccL5fv35wd3c3tElWVhZyc3NbTZs89NBDOHr0KA4dOiT/RUVFYezYsTJu7W0AAIMHD641zfrkyZPo1q0bACA8PBxBQUGGdigrK8PevXtbTTtcvXoVLi7GryVXV1eYzWYAztEGlhrzmaOjo1FSUoKMjAx5zY4dO2A2mzFgwADtdbaF64nHqVOn8M0336BDhw6G8629DcaPH48jR44YvieDg4Mxbdo0fP311wAcrA3sPeLV0ocffig8PT3FunXrxIkTJ8Rzzz0n/P39RUFBgb2rZhPPP/+88PPzEzt37hTnzp2T/65evSqvmThxoggNDRU7duwQBw4cENHR0SI6OtqOtbY9dbaLEM7RBvv27RNubm5i3rx54tSpU+L9998Xbdq0ERs3bpTXLFy4UPj7+4vPPvtMHDlyRDz22GMiPDxcXLt2zY41t54JEyaILl26iO3bt4vs7GyxZcsW0bFjR/HSSy/Ja1pjG5SXl4uDBw+KgwcPCgDi73//uzh48KCcydGYz/zII4+IPn36iL1794rdu3eLO+64Q4wZM8ZeH6nJGmqDqqoqMWLECBESEiIOHTpk+K6srKyU79Ga26AulrNdhHCcNmhxyYcQQixfvlyEhoYKDw8Pce+994r09HR7V8lmANT5b+3atfKaa9euib/85S+iffv2ok2bNuLxxx8X586ds1+lNbBMPpylDbZt2yYiIyOFp6eniIiIEGvWrDGcN5vNYtasWSIwMFB4enqKhx56SGRlZdmpttZXVlYmpkyZIkJDQ4WXl5e49dZbxV//+lfDH5jW2AYpKSl1fg9MmDBBCNG4z3zx4kUxZswY0a5dO+Hr6yueeuopUV5ebodP0zwNtUF2dna935UpKSnyPVpzG9SlruTDUdrAJISydCARERGRjbWoMR9ERETU+jH5ICIiIq2YfBAREZFWTD6IiIhIKyYfREREpBWTDyIiItKKyQcRERFpxeSDiIiItGLyQURERFox+SAiIiKtmHwQERGRVkw+iIiISKv/A9u6Qs0kyCcrAAAAAElFTkSuQmCC"},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"## Visualizing CW Adversarial Attacks","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Visualize adversarial examples generated by CW attack\ndef visualize_cw_attack(model, loader, attack, num_images=5):\n    model.eval()\n    dataiter = iter(loader)\n    images, labels = next(dataiter)  # Use next() to get the next batch\n    images, labels = images[:num_images], labels[:num_images]\n    images, labels = images.to(device), labels.to(device)\n\n    adv_images = attack(images, labels)\n    outputs = model(adv_images)\n    _, predicted = torch.max(outputs, 1)\n    predicted = predicted.cpu().numpy()\n\n    imshow(torchvision.utils.make_grid(adv_images.cpu()), title=[str(pred) for pred in predicted])","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:55:02.506545Z","iopub.execute_input":"2024-10-05T18:55:02.506907Z","iopub.status.idle":"2024-10-05T18:55:02.514589Z","shell.execute_reply.started":"2024-10-05T18:55:02.506877Z","shell.execute_reply":"2024-10-05T18:55:02.513514Z"},"trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Define CW attacks\ncw = torchattacks.CW(model, c=1e-4, kappa=0, steps=1000, lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:55:02.936602Z","iopub.execute_input":"2024-10-05T18:55:02.936905Z","iopub.status.idle":"2024-10-05T18:55:02.941656Z","shell.execute_reply.started":"2024-10-05T18:55:02.936881Z","shell.execute_reply":"2024-10-05T18:55:02.940810Z"},"trusted":true},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Visualize CW attack\nvisualize_cw_attack(model, test_loader, cw)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T18:55:03.244965Z","iopub.execute_input":"2024-10-05T18:55:03.245295Z","iopub.status.idle":"2024-10-05T18:55:12.613532Z","shell.execute_reply.started":"2024-10-05T18:55:03.245269Z","shell.execute_reply":"2024-10-05T18:55:12.612153Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize CW attack\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvisualize_cw_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcw\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[35], line 15\u001b[0m, in \u001b[0;36mvisualize_cw_attack\u001b[0;34m(model, loader, attack, num_images)\u001b[0m\n\u001b[1;32m     12\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m predicted \u001b[38;5;241m=\u001b[39m predicted\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43madv_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[31], line 5\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(img, title)\u001b[0m\n\u001b[1;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# unnormalize\u001b[39;00m\n\u001b[1;32m      4\u001b[0m npimg \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(npimg, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m title \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(title)\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"],"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error"}],"execution_count":37}]}
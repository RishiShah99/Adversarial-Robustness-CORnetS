{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shahrish99/resnet18-cifar100?scriptVersionId=256937641\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.autograd import Variable\nfrom tqdm import tqdm\nimport numpy as np\n\n# Set up data augmentation and preprocessing\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n# Load CIFAR-100 dataset\ntrainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n\ntestset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=4)\n\n# Load ResNet-18 pre-trained on ImageNet\nmodel = models.resnet18(pretrained=True)\n\n# Modify the final fully connected layer for CIFAR-100 (100 classes)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 100)\n\n# Move model to GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Function to calculate Top-k accuracy\ndef calculate_topk_accuracy(output, target, topk=(1, 5)):\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n# Training and evaluation loop\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    # Training Phase\n    model.train()\n    running_loss = 0.0\n    top1_correct = 0\n    top5_correct = 0\n    total_samples = 0\n\n    with tqdm(trainloader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Train]\") as pbar:\n        for inputs, labels in pbar:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Resize images to match pre-trained model input dimensions\n            inputs = nn.functional.interpolate(inputs, size=(224, 224))\n\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            total_samples += labels.size(0)\n\n            # Calculate Top-1 and Top-5 accuracy\n            top1, top5 = calculate_topk_accuracy(outputs, labels, topk=(1, 5))\n            top1_correct += top1.item() * labels.size(0) / 100.0\n            top5_correct += top5.item() * labels.size(0) / 100.0\n\n            pbar.set_postfix({\n                'Loss': running_loss / total_samples,\n                'Top-1 Accuracy': 100.0 * top1_correct / total_samples,\n                'Top-5 Accuracy': 100.0 * top5_correct / total_samples\n            })\n\n    # Evaluation Phase\n    model.eval()\n    test_loss = 0.0\n    top1_correct = 0\n    top5_correct = 0\n    total_samples = 0\n\n    with tqdm(testloader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Test]\") as pbar:\n        with torch.no_grad():\n            for inputs, labels in pbar:\n                inputs, labels = inputs.to(device), labels.to(device)\n                inputs = nn.functional.interpolate(inputs, size=(224, 224))\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                test_loss += loss.item()\n                total_samples += labels.size(0)\n\n                # Calculate Top-1 and Top-5 accuracy\n                top1, top5 = calculate_topk_accuracy(outputs, labels, topk=(1, 5))\n                top1_correct += top1.item() * labels.size(0) / 100.0\n                top5_correct += top5.item() * labels.size(0) / 100.0\n\n                pbar.set_postfix({\n                    'Loss': test_loss / total_samples,\n                    'Top-1 Accuracy': 100.0 * top1_correct / total_samples,\n                    'Top-5 Accuracy': 100.0 * top5_correct / total_samples\n                })\n\n# Save the model\ntorch.save(model.state_dict(), 'resnet18_cifar100_tqdm.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:03:07.631477Z","iopub.execute_input":"2024-12-22T15:03:07.631871Z","iopub.status.idle":"2024-12-22T15:30:58.93981Z","shell.execute_reply.started":"2024-12-22T15:03:07.631835Z","shell.execute_reply":"2024-12-22T15:30:58.938978Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 [Train]: 100%|██████████| 391/391 [02:38<00:00,  2.47it/s, Loss=0.0145, Top-1 Accuracy=49.9, Top-5 Accuracy=80.5]\nEpoch 1/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.17it/s, Loss=0.0134, Top-1 Accuracy=53.4, Top-5 Accuracy=83.8]\nEpoch 2/10 [Train]: 100%|██████████| 391/391 [02:37<00:00,  2.49it/s, Loss=0.00921, Top-1 Accuracy=65.7, Top-5 Accuracy=91.2]\nEpoch 2/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.16it/s, Loss=0.0118, Top-1 Accuracy=59.8, Top-5 Accuracy=87.5]\nEpoch 3/10 [Train]: 100%|██████████| 391/391 [02:36<00:00,  2.50it/s, Loss=0.00745, Top-1 Accuracy=71.5, Top-5 Accuracy=94]  \nEpoch 3/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.18it/s, Loss=0.00952, Top-1 Accuracy=66.1, Top-5 Accuracy=90.8]\nEpoch 4/10 [Train]: 100%|██████████| 391/391 [02:36<00:00,  2.50it/s, Loss=0.00633, Top-1 Accuracy=75.5, Top-5 Accuracy=95.6]\nEpoch 4/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.17it/s, Loss=0.00867, Top-1 Accuracy=69.6, Top-5 Accuracy=92.4]\nEpoch 5/10 [Train]: 100%|██████████| 391/391 [02:36<00:00,  2.50it/s, Loss=0.00541, Top-1 Accuracy=78.8, Top-5 Accuracy=96.7]\nEpoch 5/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.17it/s, Loss=0.00922, Top-1 Accuracy=69.1, Top-5 Accuracy=91.9]\nEpoch 6/10 [Train]: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s, Loss=0.00465, Top-1 Accuracy=81.4, Top-5 Accuracy=97.6]\nEpoch 6/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.15it/s, Loss=0.00889, Top-1 Accuracy=69.9, Top-5 Accuracy=92.5]\nEpoch 7/10 [Train]: 100%|██████████| 391/391 [02:37<00:00,  2.49it/s, Loss=0.00413, Top-1 Accuracy=83.3, Top-5 Accuracy=98.1]\nEpoch 7/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.18it/s, Loss=0.00855, Top-1 Accuracy=71.5, Top-5 Accuracy=92.9]\nEpoch 8/10 [Train]: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s, Loss=0.00356, Top-1 Accuracy=85.5, Top-5 Accuracy=98.6]\nEpoch 8/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.17it/s, Loss=0.00892, Top-1 Accuracy=71.5, Top-5 Accuracy=93.1]\nEpoch 9/10 [Train]: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s, Loss=0.0031, Top-1 Accuracy=87.3, Top-5 Accuracy=99]   \nEpoch 9/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.16it/s, Loss=0.00893, Top-1 Accuracy=72.6, Top-5 Accuracy=93.2]\nEpoch 10/10 [Train]: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s, Loss=0.00278, Top-1 Accuracy=88.7, Top-5 Accuracy=99.1]\nEpoch 10/10 [Test]: 100%|██████████| 79/79 [00:09<00:00,  8.15it/s, Loss=0.00881, Top-1 Accuracy=73.1, Top-5 Accuracy=93.4]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install torchattacks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:45:21.950669Z","iopub.execute_input":"2024-12-22T15:45:21.951471Z","iopub.status.idle":"2024-12-22T15:45:32.649746Z","shell.execute_reply.started":"2024-12-22T15:45:21.951431Z","shell.execute_reply":"2024-12-22T15:45:32.648567Z"}},"outputs":[{"name":"stdout","text":"Collecting torchattacks\n  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (2.4.0)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (0.19.0)\nRequirement already satisfied: scipy>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.14.1)\nRequirement already satisfied: tqdm>=4.56.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (4.66.4)\nCollecting requests~=2.25.1 (from torchattacks)\n  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.26.4)\nCollecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (2024.6.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (2024.6.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8.2->torchattacks) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\nDownloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: idna, chardet, requests, torchattacks\n  Attempting uninstall: idna\n    Found existing installation: idna 3.7\n    Uninstalling idna-3.7:\n      Successfully uninstalled idna-3.7\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.3\n    Uninstalling requests-2.32.3:\n      Successfully uninstalled requests-2.32.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.1.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\nbeatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.3.1 which is incompatible.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.3 which is incompatible.\nbigframes 0.22.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\nconda 24.5.0 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\nconda 24.5.0 requires requests<3,>=2.28.0, but you have requests 2.25.1 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.10.1 which is incompatible.\ndatasets 3.1.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\ndocker 7.1.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ngcsfs 2024.9.0.post1 requires fsspec==2024.9.0, but you have fsspec 2024.6.0 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\njupyterlab 4.3.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-server 2.27.2 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.12.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.5.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torchattacks\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Define attack methods\npgd_attack = torchattacks.PGD(model, eps=0.3, alpha=2/255, steps=40)\ncw_attack = torchattacks.CW(model, c=1e-4, kappa=0, steps=100, lr=0.01)\nfgsm_attack = torchattacks.FGSM(model, eps=0.3)\n\n# Helper function to evaluate the model on adversarial examples\ndef evaluate_adversarial_attack(attack, attack_name, dataloader):\n    total_samples = 0\n    correct_top1 = 0\n    correct_top5 = 0\n\n    print(f\"\\nEvaluating {attack_name} Attack...\")\n    for images, labels in tqdm(dataloader, desc=f\"{attack_name} Attack\"):\n        images, labels = images.cuda(), labels.cuda()\n\n        # Generate adversarial examples\n        adv_images = attack(images, labels)\n\n        # Evaluate on the adversarial examples\n        outputs = model(adv_images)\n        _, predicted = outputs.topk(5, 1, True, True)\n\n        total_samples += labels.size(0)\n        correct_top1 += (predicted[:, 0] == labels).sum().item()\n        correct_top5 += sum([1 if labels[i] in predicted[i] else 0 for i in range(labels.size(0))])\n\n    top1_acc = 100 * correct_top1 / total_samples\n    top5_acc = 100 * correct_top5 / total_samples\n    print(f\"{attack_name} Top-1 Accuracy: {top1_acc:.2f}%\")\n    print(f\"{attack_name} Top-5 Accuracy: {top5_acc:.2f}%\")\n    return top1_acc, top5_acc\n\npgd_top1, pgd_top5 = evaluate_adversarial_attack(pgd_attack, \"PGD\", testloader)\ncw_top1, cw_top5 = evaluate_adversarial_attack(cw_attack, \"CW\", testloader)\nfgsm_top1, fgsm_top5 = evaluate_adversarial_attack(fgsm_attack, \"FGSM\", testloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:57:53.177661Z","iopub.execute_input":"2024-12-22T15:57:53.178703Z","iopub.status.idle":"2024-12-22T16:00:13.009362Z","shell.execute_reply.started":"2024-12-22T15:57:53.178665Z","shell.execute_reply":"2024-12-22T16:00:13.008196Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating PGD Attack...\n","output_type":"stream"},{"name":"stderr","text":"PGD Attack: 100%|██████████| 79/79 [01:21<00:00,  1.03s/it]\n","output_type":"stream"},{"name":"stdout","text":"PGD Top-1 Accuracy: 0.00%\nPGD Top-5 Accuracy: 0.02%\n\nEvaluating CW Attack...\n","output_type":"stream"},{"name":"stderr","text":"CW Attack: 100%|██████████| 79/79 [00:55<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"CW Top-1 Accuracy: 1.34%\nCW Top-5 Accuracy: 10.13%\n\nEvaluating FGSM Attack...\n","output_type":"stream"},{"name":"stderr","text":"FGSM Attack: 100%|██████████| 79/79 [00:03<00:00, 24.91it/s]","output_type":"stream"},{"name":"stdout","text":"FGSM Top-1 Accuracy: 0.22%\nFGSM Top-5 Accuracy: 2.11%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14}]}
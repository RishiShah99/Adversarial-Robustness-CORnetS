{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:55:37.216623Z","iopub.execute_input":"2025-07-04T22:55:37.217233Z","iopub.status.idle":"2025-07-04T22:55:37.221689Z","shell.execute_reply.started":"2025-07-04T22:55:37.217210Z","shell.execute_reply":"2025-07-04T22:55:37.221147Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:55:37.608282Z","iopub.execute_input":"2025-07-04T22:55:37.608551Z","iopub.status.idle":"2025-07-04T22:55:37.612696Z","shell.execute_reply.started":"2025-07-04T22:55:37.608531Z","shell.execute_reply":"2025-07-04T22:55:37.612026Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Model Set Up:","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:55:38.512451Z","iopub.execute_input":"2025-07-04T22:55:38.513134Z","iopub.status.idle":"2025-07-04T22:55:38.517183Z","shell.execute_reply.started":"2025-07-04T22:55:38.513111Z","shell.execute_reply":"2025-07-04T22:55:38.516446Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"class DenoiseBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n        self.relu = nn.ReLU()\n        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n\n    def forward(self, x):\n        return x - self.conv2(self.relu(self.conv1(x)))\n        \nclass CORblock_S_Robust(nn.Module):\n    def __init__(self, in_channels, out_channels, scale=4, steps=2):\n        super().__init__()\n        self.steps = steps\n\n        self.conv_input = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n        self.skip = nn.Conv2d(out_channels, out_channels, 1, stride=2, bias=False)\n        self.norm_skip = nn.BatchNorm2d(out_channels)\n\n        self.conv1 = nn.Conv2d(out_channels, out_channels * scale, 1, bias=False)\n        self.conv2 = nn.Conv2d(out_channels * scale, out_channels * scale, 3, stride=2, padding=1, bias=False)\n        self.conv3 = nn.Conv2d(out_channels * scale, out_channels, 1, bias=False)\n\n        self.denoise = DenoiseBlock(out_channels * scale)\n        self.skip_gate = nn.Conv2d(out_channels, out_channels, 1)\n        self.nonlin = nn.ReLU(inplace=True)\n\n        self.norm1 = nn.ModuleList([nn.BatchNorm2d(out_channels * scale) for _ in range(steps)])\n        self.norm2 = nn.ModuleList([nn.BatchNorm2d(out_channels * scale) for _ in range(steps)])\n        self.norm3 = nn.ModuleList([nn.BatchNorm2d(out_channels) for _ in range(steps)])\n\n    def forward(self, x):\n        x = self.conv_input(x)\n\n        for step in range(self.steps):\n            residual = self.skip(x)\n            residual = self.norm_skip(residual)\n\n            out = self.conv1(x)\n            out = self.norm1[step](out)\n            out = self.nonlin(out)\n\n            out = self.conv2(out)\n            out = self.norm2[step](out)\n            out = self.nonlin(out)\n\n            out = self.denoise(out)\n\n            out = self.conv3(out)\n            out = self.norm3[step](out)\n\n            gate = torch.sigmoid(self.skip_gate(out))\n            x = self.nonlin(gate * residual + (1 - gate) * out)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:55:40.200941Z","iopub.execute_input":"2025-07-04T22:55:40.201529Z","iopub.status.idle":"2025-07-04T22:55:40.210691Z","shell.execute_reply.started":"2025-07-04T22:55:40.201507Z","shell.execute_reply":"2025-07-04T22:55:40.210104Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class CORNet_S_Robust(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.V1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Identity()\n        )\n\n        self.V2 = CORblock_S_Robust(64, 128, steps=2)\n        self.V4 = CORblock_S_Robust(128, 256, steps=4)\n        self.IT = CORblock_S_Robust(256, 512, steps=2)\n\n        self.decoder = nn.Sequential(\n            nn.AdaptiveAvgPool2d(output_size=1),\n            nn.Flatten(),\n            nn.Linear(512, num_classes),\n            nn.Identity()\n        )\n\n    def forward(self, x):\n        x = self.V1(x)\n        x = self.V2(x)\n        x = self.V4(x)\n        x = self.IT(x)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:55:41.658508Z","iopub.execute_input":"2025-07-04T22:55:41.659203Z","iopub.status.idle":"2025-07-04T22:55:41.664912Z","shell.execute_reply.started":"2025-07-04T22:55:41.659180Z","shell.execute_reply":"2025-07-04T22:55:41.664312Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model = CORNet_S_Robust(num_classes=10).to(device)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:55:43.536355Z","iopub.execute_input":"2025-07-04T22:55:43.536918Z","iopub.status.idle":"2025-07-04T22:55:45.018611Z","shell.execute_reply.started":"2025-07-04T22:55:43.536896Z","shell.execute_reply":"2025-07-04T22:55:45.017568Z"}},"outputs":[{"name":"stdout","text":"CORNet_S_Robust(\n  (V1): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU(inplace=True)\n    (7): Identity()\n  )\n  (V2): CORblock_S_Robust(\n    (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (denoise): DenoiseBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (relu): ReLU()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (skip_gate): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n    (nonlin): ReLU(inplace=True)\n    (norm1): ModuleList(\n      (0-1): 2 x BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (norm2): ModuleList(\n      (0-1): 2 x BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (norm3): ModuleList(\n      (0-1): 2 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (V4): CORblock_S_Robust(\n    (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (denoise): DenoiseBlock(\n      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (relu): ReLU()\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (skip_gate): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n    (nonlin): ReLU(inplace=True)\n    (norm1): ModuleList(\n      (0-3): 4 x BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (norm2): ModuleList(\n      (0-3): 4 x BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (norm3): ModuleList(\n      (0-3): 4 x BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (IT): CORblock_S_Robust(\n    (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (denoise): DenoiseBlock(\n      (conv1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (relu): ReLU()\n      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (skip_gate): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n    (nonlin): ReLU(inplace=True)\n    (norm1): ModuleList(\n      (0-1): 2 x BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (norm2): ModuleList(\n      (0-1): 2 x BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (norm3): ModuleList(\n      (0-1): 2 x BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (decoder): Sequential(\n    (0): AdaptiveAvgPool2d(output_size=1)\n    (1): Flatten(start_dim=1, end_dim=-1)\n    (2): Linear(in_features=512, out_features=10, bias=True)\n    (3): Identity()\n  )\n)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),              # Resize to what CORNet-S expects\n    transforms.Grayscale(num_output_channels=3),# Convert 1-channel MNIST to 3\n    transforms.ToTensor()\n])\n\ntrain_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_set  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=1000, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:55:45.019831Z","iopub.execute_input":"2025-07-04T22:55:45.020120Z","iopub.status.idle":"2025-07-04T22:55:45.126083Z","shell.execute_reply.started":"2025-07-04T22:55:45.020091Z","shell.execute_reply":"2025-07-04T22:55:45.125348Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(model, device, train_loader, optimizer, epoch, criterion):\n    model.train()\n    pbar = tqdm(train_loader, desc=f\"Train Epoch {epoch}\")\n    running_loss, correct, total = 0, 0, 0\n\n    for data, target in pbar:\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * data.size(0)\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n\n        pbar.set_postfix(loss=running_loss/total, acc=correct/total)\n\n    return running_loss / total, correct / total\n\n\ndef test(model, device, test_loader, criterion):\n    model.eval()\n    pbar = tqdm(test_loader, desc=\"Testing\")\n    running_loss, correct, total = 0, 0, 0\n\n    with torch.no_grad():\n        for data, target in pbar:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            loss = criterion(output, target)\n\n            running_loss += loss.item() * data.size(0)\n            pred = output.argmax(dim=1)\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            pbar.set_postfix(loss=running_loss/total, acc=correct/total)\n\n    return running_loss / total, correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:55:46.505010Z","iopub.execute_input":"2025-07-04T22:55:46.505329Z","iopub.status.idle":"2025-07-04T22:55:46.512994Z","shell.execute_reply.started":"2025-07-04T22:55:46.505305Z","shell.execute_reply":"2025-07-04T22:55:46.512071Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nepochs = 5\n\n# Robust CORNet-S\nrobust_model = CORNet_S_Robust(num_classes=10).to(device)\nrobust_optimizer = optim.Adam(robust_model.parameters(), lr=0.001)\n\nbest_acc = 0.0  # Track best test accuracy\n\nfor epoch in range(1, epochs + 1):\n    print(f\"\\n--- Epoch {epoch} ---\")\n    print(\"\\nTraining CORNet-S-Robust\")\n    train(robust_model, device, train_loader, robust_optimizer, epoch, criterion)\n    \n    print(\"Testing CORNet-S-Robust\")\n    test_loss, test_acc = test(robust_model, device, test_loader, criterion)  # <- updated unpacking\n\n    print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n\n    # Save best model\n    if test_acc > best_acc:\n        best_acc = test_acc\n        torch.save(robust_model.state_dict(), \"best_robust_model.pth\")\n        print(f\"✅ New best model saved with accuracy: {best_acc * 100:.2f}%\")\n    else:\n        print(f\"No improvement. Best remains: {best_acc * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:55:51.455525Z","iopub.execute_input":"2025-07-04T22:55:51.455756Z"}},"outputs":[{"name":"stdout","text":"\n--- Epoch 1 ---\n\nTraining CORNet-S-Robust\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 1:  69%|██████▉   | 1291/1875 [19:44<08:54,  1.09it/s, acc=0.876, loss=0.405]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"torch.save(robust_model.state_dict(), \"/kaggle/working/cornet_s_robust_mnist.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:42:54.097615Z","iopub.execute_input":"2025-07-04T22:42:54.097872Z","iopub.status.idle":"2025-07-04T22:42:55.308712Z","shell.execute_reply.started":"2025-07-04T22:42:54.097853Z","shell.execute_reply":"2025-07-04T22:42:55.308112Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"!pip install -q torchattacks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:43:07.749451Z","iopub.execute_input":"2025-07-04T22:43:07.750006Z","iopub.status.idle":"2025-07-04T22:44:40.299274Z","shell.execute_reply.started":"2025-07-04T22:43:07.749984Z","shell.execute_reply":"2025-07-04T22:44:40.298467Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibpysal 4.9.2 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ndatasets 3.6.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\njupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\ntiktoken 0.9.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ndocker 7.1.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.25.1 which is incompatible.\nbigframes 1.42.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\nyfinance 0.2.55 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\nsphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.25.1 which is incompatible.\ngoogle-genai 1.9.0 requires requests<3.0.0,>=2.28.1, but you have requests 2.25.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntweepy 4.15.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/input/cornet_s__robust_mnist/pytorch/default/1/cornet_s_robust_mnist.pth\", map_location = device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T20:36:25.758496Z","iopub.execute_input":"2025-07-04T20:36:25.758758Z","iopub.status.idle":"2025-07-04T20:36:29.891894Z","shell.execute_reply.started":"2025-07-04T20:36:25.758734Z","shell.execute_reply":"2025-07-04T20:36:29.891046Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\ntest(robust_model, device, test_loader, criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:44:40.300867Z","iopub.execute_input":"2025-07-04T22:44:40.301180Z","iopub.status.idle":"2025-07-04T22:44:48.642111Z","shell.execute_reply.started":"2025-07-04T22:44:40.301135Z","shell.execute_reply":"2025-07-04T22:44:48.641388Z"}},"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 10/10 [00:08<00:00,  1.20it/s, acc=0.647, loss=0.894]\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(0.893600982427597, 0.6469)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from torchattacks import PGD, CW\n\ndef evaluate_attack(model, attack, test_loader, name=\"Attack\"):\n    model.eval()\n    correct, total = 0, 0\n    pbar = tqdm(test_loader, desc=name)\n\n    for data, target in pbar:\n        data, target = data.to(device), target.to(device)\n        adv_data = attack(data, target)\n\n        output = model(adv_data)\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n\n        pbar.set_postfix(acc=correct/total)\n\n    acc = correct / total\n    print(f\"{name} Accuracy: {acc*100:.2f}%\")\n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T16:43:10.156743Z","iopub.execute_input":"2025-06-25T16:43:10.157620Z","iopub.status.idle":"2025-06-25T16:44:27.255520Z","shell.execute_reply.started":"2025-06-25T16:43:10.157589Z","shell.execute_reply":"2025-06-25T16:44:27.254771Z"}},"outputs":[{"name":"stderr","text":"Adversarial Test (PGD): 100%|██████████| 10/10 [01:17<00:00,  7.71s/it]","output_type":"stream"},{"name":"stdout","text":"📊 PGD Accuracy (ε=0.1): 0.0534\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Re-load if needed:\n# baseline_model.load_state_dict(torch.load(\"/kaggle/working/cornet_s_mnist.pth\"))\n# robust_model.load_state_dict(torch.load(\"/kaggle/working/cornet_s_robust_mnist.pth\"))\n# baseline_model.to(device).eval()\n# robust_model.to(device).eval()\n\npgd_baseline = PGD(baseline_model, eps=0.3, alpha=2/255, steps=40)\npgd_robust = PGD(robust_model, eps=0.3, alpha=2/255, steps=40)\n\ncw_baseline = CW(baseline_model, c=1e-4, kappa=0, steps=100, lr=0.01)\ncw_robust = CW(robust_model, c=1e-4, kappa=0, steps=100, lr=0.01)\n\nprint(\"\\n=== PGD Attack ===\")\nevaluate_attack(baseline_model, pgd_baseline, test_loader, name=\"PGD Baseline\")\nevaluate_attack(robust_model, pgd_robust, test_loader, name=\"PGD Robust\")\n\nprint(\"\\n=== CW Attack ===\")\nevaluate_attack(baseline_model, cw_baseline, test_loader, name=\"CW Baseline\")\nevaluate_attack(robust_model, cw_robust, test_loader, name=\"CW Robust\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T16:53:01.294703Z","iopub.execute_input":"2025-06-25T16:53:01.295423Z","iopub.status.idle":"2025-06-25T16:57:27.239055Z","shell.execute_reply.started":"2025-06-25T16:53:01.295397Z","shell.execute_reply":"2025-06-25T16:57:27.238296Z"}},"outputs":[{"name":"stderr","text":"Adversarial Test (CW): 100%|██████████| 10/10 [04:25<00:00, 26.59s/it]","output_type":"stream"},{"name":"stdout","text":"📊 CW Accuracy (c=0.1, kappa=0): 0.9458\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Another Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:57:02.744907Z","iopub.execute_input":"2025-06-26T19:57:02.745162Z","iopub.status.idle":"2025-06-26T19:57:15.847907Z","shell.execute_reply.started":"2025-06-26T19:57:02.745144Z","shell.execute_reply":"2025-06-26T19:57:15.847311Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class GatedRecurrentBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, timesteps=3):\n        super().__init__()\n        self.timesteps = timesteps\n        self.conv_input = nn.Conv2d(in_channels, out_channels, kernel_size, padding=1)\n        self.conv_gate = nn.Conv2d(out_channels, out_channels, kernel_size, padding=1)\n        self.norm = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        h = self.norm(self.conv_input(x))\n        h_list = []\n        for _ in range(self.timesteps):\n            gate = torch.sigmoid(self.conv_gate(h))\n            h = gate * self.norm(self.conv_input(x)) + (1 - gate) * h\n            h_list.append(h)\n        return torch.mean(torch.stack(h_list), dim=0) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:57:15.849086Z","iopub.execute_input":"2025-06-26T19:57:15.849453Z","iopub.status.idle":"2025-06-26T19:57:15.855306Z","shell.execute_reply.started":"2025-06-26T19:57:15.849425Z","shell.execute_reply":"2025-06-26T19:57:15.854502Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class ResidualDenoiseBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n        self.relu = nn.ReLU()\n        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n        self.scale = nn.Parameter(torch.tensor(0.5))  # learnable weight\n\n    def forward(self, x):\n        denoised = self.conv2(self.relu(self.conv1(x)))\n        return x + self.scale * denoised ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:57:15.859342Z","iopub.execute_input":"2025-06-26T19:57:15.859549Z","iopub.status.idle":"2025-06-26T19:57:15.880269Z","shell.execute_reply.started":"2025-06-26T19:57:15.859532Z","shell.execute_reply":"2025-06-26T19:57:15.879721Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class CORNet_S_RD_V2(nn.Module):\n    def __init__(self, num_classes=10, timesteps=3):\n        super().__init__()\n        self.input_filter = nn.Conv2d(1, 1, kernel_size=1)  # learnable input prefilter\n\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(2, 2)\n\n        self.block1 = GatedRecurrentBlock(32, 64, timesteps=timesteps)\n        self.block2 = GatedRecurrentBlock(64, 128, timesteps=timesteps)\n        self.block3 = GatedRecurrentBlock(128, 128, timesteps=timesteps)\n\n        self.denoise = ResidualDenoiseBlock(128)\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = self.input_filter(x)\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.block1(x)\n        x = self.pool(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.denoise(x)\n        x = self.gap(x).squeeze(-1).squeeze(-1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:57:15.880912Z","iopub.execute_input":"2025-06-26T19:57:15.881170Z","iopub.status.idle":"2025-06-26T19:57:15.897838Z","shell.execute_reply.started":"2025-06-26T19:57:15.881147Z","shell.execute_reply":"2025-06-26T19:57:15.897390Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"transform = transforms.ToTensor()\n\ntrain_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=1000, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:57:15.898427Z","iopub.execute_input":"2025-06-26T19:57:15.898691Z","iopub.status.idle":"2025-06-26T19:57:18.237277Z","shell.execute_reply.started":"2025-06-26T19:57:15.898670Z","shell.execute_reply":"2025-06-26T19:57:18.236370Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 37.8MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 1.00MB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 9.64MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 6.88MB/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CORNet_S_RD_V2().to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\nfor epoch in range(5):\n    model.train()\n    total_loss = 0\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        output = model(x)\n        loss = criterion(output, y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:57:18.238158Z","iopub.execute_input":"2025-06-26T19:57:18.238408Z","iopub.status.idle":"2025-06-26T19:59:08.557662Z","shell.execute_reply.started":"2025-06-26T19:57:18.238389Z","shell.execute_reply":"2025-06-26T19:59:08.556691Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Loss = 0.2463\nEpoch 2: Loss = 0.0846\nEpoch 3: Loss = 0.0625\nEpoch 4: Loss = 0.0522\nEpoch 5: Loss = 0.0431\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for x, y in test_loader:\n        x, y = x.to(device), y.to(device)\n        output = model(x)\n        pred = output.argmax(dim=1)\n        correct += (pred == y).sum().item()\n        total += y.size(0)\nprint(f\"Clean Accuracy: {correct / total * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:59:08.558699Z","iopub.execute_input":"2025-06-26T19:59:08.559005Z","iopub.status.idle":"2025-06-26T19:59:10.595858Z","shell.execute_reply.started":"2025-06-26T19:59:08.558975Z","shell.execute_reply":"2025-06-26T19:59:10.595240Z"}},"outputs":[{"name":"stdout","text":"Clean Accuracy: 98.61%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"torch.save(model.state_dict(), \"cornet_s_rd_mnist_new.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:28:16.265377Z","iopub.execute_input":"2025-06-26T20:28:16.266109Z","iopub.status.idle":"2025-06-26T20:28:16.289086Z","shell.execute_reply.started":"2025-06-26T20:28:16.266069Z","shell.execute_reply":"2025-06-26T20:28:16.288066Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\n\n# ---------------- PGD Attack Setup ----------------\npgd_eps = 0.001        # Default MNIST perturbation\npgd_alpha = 2/255\npgd_steps = 40\n\npgd_attack = torchattacks.PGD(model, eps=pgd_eps, alpha=pgd_alpha, steps=pgd_steps)\n\n# ---------------- PGD Adversarial Accuracy Function ----------------\ndef adversarial_test_pgd(attack, loader):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    for inputs, labels in tqdm(loader, desc=f\"Adversarial Test (PGD)\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        adv_inputs = attack(inputs, labels)\n        outputs = model(adv_inputs)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(labels).sum().item()\n        total += labels.size(0)\n    \n    acc = correct / total\n    print(f\"📊 PGD Accuracy (ε={pgd_eps}): {acc:.4f}\")\n    return acc\n\n# ---------------- Run PGD Evaluation ----------------\npgd_acc = adversarial_test_pgd(pgd_attack, test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:35:12.617218Z","iopub.execute_input":"2025-06-26T20:35:12.617530Z","iopub.status.idle":"2025-06-26T20:36:38.170757Z","shell.execute_reply.started":"2025-06-26T20:35:12.617507Z","shell.execute_reply":"2025-06-26T20:36:38.170165Z"}},"outputs":[{"name":"stderr","text":"Adversarial Test (PGD): 100%|██████████| 10/10 [01:25<00:00,  8.55s/it]","output_type":"stream"},{"name":"stdout","text":"📊 PGD Accuracy (ε=0.001): 0.9858\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ---------------- CW Attack Setup ----------------\ncw_c = 1e-3          # L2 perturbation penalty\ncw_kappa = 0         # Confidence\ncw_steps = 100\ncw_lr = 0.01\n\ncw_attack = torchattacks.CW(model, c=cw_c, kappa=cw_kappa, steps=cw_steps, lr=cw_lr)\n\n# ---------------- CW Adversarial Accuracy Function ----------------\ndef adversarial_test_cw(attack, loader):\n    model.eval()\n    correct = 0\n    total = 0\n\n    for inputs, labels in tqdm(loader, desc=f\"Adversarial Test (CW)\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        adv_inputs = attack(inputs, labels)\n        outputs = model(adv_inputs)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(labels).sum().item()\n        total += labels.size(0)\n\n    acc = correct / total\n    print(f\"📊 CW Accuracy (c={cw_c}, kappa={cw_kappa}): {acc:.4f}\")\n    return acc\n\n# ---------------- Run CW Evaluation ----------------\ncw_acc = adversarial_test_cw(cw_attack, test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:01:00.255596Z","iopub.execute_input":"2025-06-26T21:01:00.256388Z","iopub.status.idle":"2025-06-26T21:01:35.382393Z","shell.execute_reply.started":"2025-06-26T21:01:00.256364Z","shell.execute_reply":"2025-06-26T21:01:35.381686Z"}},"outputs":[{"name":"stderr","text":"Adversarial Test (CW): 100%|██████████| 10/10 [00:35<00:00,  3.51s/it]","output_type":"stream"},{"name":"stdout","text":"📊 CW Accuracy (c=0.001, kappa=0): 0.9857\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}